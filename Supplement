# ==================================================================
# Supplementary 4E: Master Workflow Script
# ==================================================================

# --- Packages ------------------------------------------------------
library(readxl)       # read_excel
library(lmtest)       # bptest, dwtest, waldtest, coeftest
library(sandwich)     # vcovHC, vcovCL, NeweyWest
library(car)          # ncvTest, vif
library(strucchange)  # sctest (Rainbow)
library(broom)        # tidy
library(ggplot2)      # plots
library(dplyr)        # summaries
library(moments)      # skewness, kurtosis

# ==================================================================
# S1. Data preparation & filtering
# ==================================================================
d <- read_excel(
  "D:/Documents/PhD/Arbeitsdateien/Dataset 2. Arbeit/
   Waste Treatment Data set_Outliers-Removed_Pooled_CoreVariables_Excl.BeneficiaryProxy.xlsx",
  sheet = 1
)

# Initial fit for Cook’s distance
m0 <- lm(Value ~ GDP_per_Capita + log(OrganicLandShare + 1) +
            Population_Density + Average_Farm_Size + Publication_Year,
         data = d)

# Drop high-leverage obs (Cook’s D > 4/n)
d <- d[-which(cooks.distance(m0) > 4 / nrow(d)), ]

# Center publication year
yr_mean <- mean(d$Publication_Year, na.rm = TRUE)
d$Publication_Year_c <- d$Publication_Year - yr_mean

# ==================================================================
# S2. Core regression models
# ==================================================================
m <- lm(Value ~ GDP_per_Capita + log(OrganicLandShare + 1) +
           Population_Density + Average_Farm_Size + Publication_Year_c,
        data = d)

rob <- vcovHC(m, type = "HC1")
tbl <- broom::tidy(m, conf.int = TRUE, vcov = rob)
adj_r2 <- summary(m)$adj.r.squared
wald <- waldtest(m, vcov = rob, test = "F")

# Newey–West HAC
vcov_nw  <- NeweyWest(m, lag = 2, prewhite = FALSE)
tbl_nw   <- broom::tidy(m, conf.int = TRUE, vcov = vcov_nw)
wald_nw  <- waldtest(m, vcov = vcov_nw, test = "F")

# Log(Value) model
m_log <- lm(log(Value) ~ GDP_per_Capita + log(OrganicLandShare + 1) +
                           Population_Density + Average_Farm_Size + Publication_Year_c,
            data = d)
rob_log <- vcovHC(m_log, "HC1")
tbl_log <- broom::tidy(m_log, conf.int = TRUE, vcov = rob_log)
wald_log <- waldtest(m_log, vcov = rob_log, test = "F")

# Significance comparison
lvl <- broom::tidy(m, vcov = rob)
lg  <- broom::tidy(m_log, vcov = rob_log)
common <- intersect(lvl$term, lg$term)
cmp <- data.frame(
  term = common[common != "(Intercept)"],
  same_sign = sign(coef(m)[common[-1]]) == sign(coef(m_log)[common[-1]]),
  same_sig_5pct = (lvl$p.value[match(common, lvl$term)][-1] < 0.05) ==
                  (lg$p.value [match(common, lg$term)][-1] < 0.05)
)

# ==================================================================
# S3. Diagnostics & robustness
# ==================================================================
diag_out <- list(
  Rainbow_23 = sctest(m, type = "Rainbow")$p.value,
  Rainbow_50 = sctest(m, type = "Rainbow", frac = 0.5)$p.value,
  BP         = bptest(m)$p.value,
  NCV        = ncvTest(m)$p,
  DW         = dwtest(m)$p.value,
  VIF        = vif(m),
  SW_levels  = shapiro.test(residuals(m))$p.value,
  SW_logDV   = shapiro.test(residuals(m_log))$p.value
)

# Clustered SEs (if StudyID available)
if ("StudyID" %in% names(d)) {
  cl_vcov <- vcovCL(m, cluster = d$StudyID, type = "HC1")
  clustered_tbl <- broom::tidy(m, conf.int = TRUE, vcov = cl_vcov)
} else {
  clustered_tbl <- NULL
}

# Leave-one-study-out (LOSO)
groups <- if ("StudyID" %in% names(d)) unique(d$StudyID) else seq_len(nrow(d))
loso <- lapply(groups, function(g) {
  d_sub <- if ("StudyID" %in% names(d)) subset(d, StudyID != g) else d[-g, ]
  fit   <- try(lm(Value ~ GDP_per_Capita + log(OrganicLandShare + 1) +
                    Population_Density + Average_Farm_Size + Publication_Year_c,
                  data = d_sub), silent = TRUE)
  if (inherits(fit, "try-error")) return(data.frame(GDPpc = NA, p_GDPpc = NA))
  hc1 <- vcovHC(fit, "HC1")
  out <- coeftest(fit, vcov = hc1)
  data.frame(
    GDPpc   = coef(fit)["GDP_per_Capita"],
    p_GDPpc = out["GDP_per_Capita", "Pr(>|t|)"]
  )
})
loso_df <- do.call(rbind, loso)
loso_summary <- list(
  GDPpc_min = min(loso_df$GDPpc, na.rm = TRUE),
  GDPpc_max = max(loso_df$GDPpc, na.rm = TRUE),
  p_min     = min(loso_df$p_GDPpc, na.rm = TRUE),
  p_max     = max(loso_df$p_GDPpc, na.rm = TRUE)
)

# ==================================================================
# S4. Predictive validation (LOOCV)
# ==================================================================
n <- nrow(d)
preds <- errors <- numeric(n)
for (i in 1:n) {
  fit <- lm(Value ~ GDP_per_Capita + log(OrganicLandShare + 1) +
              Population_Density + Average_Farm_Size + Publication_Year,
            data = d[-i, ])
  preds[i] <- predict(fit, newdata = d[i, , drop = FALSE])
  errors[i] <- d$Value[i] - preds[i]
}
results_loocv <- data.frame(Row = 1:n, Actual = d$Value,
                            Predicted = preds, Error = errors)
summary_stats <- results_loocv %>%
  summarise(Mean_Error = mean(Error),
            Median_Error = median(Error),
            RMSE = sqrt(mean(Error^2)),
            MAE = mean(abs(Error)))

# ==================================================================
# S5. Case study predictions
# ==================================================================
x_bav <- data.frame(GDP_per_Capita=48247, OrganicLandShare=0.123,
                    Population_Density=316, Average_Farm_Size=37.0,
                    Publication_Year_c=0)
x_bw  <- data.frame(GDP_per_Capita=50289, OrganicLandShare=0.121,
                    Population_Density=190, Average_Farm_Size=36.9,
                    Publication_Year_c=0)

pred_bav <- predict(m, newdata = x_bav, se.fit = TRUE)
pred_bw  <- predict(m, newdata = x_bw, se.fit = TRUE)

# ==================================================================
# S6. Descriptives & figures
# ==================================================================

# Outcome distribution
x <- d$Value
outcome_stats <- list(
  mean   = mean(x, na.rm = TRUE),
  sd     = sd(x, na.rm = TRUE),
  min    = min(x, na.rm = TRUE),
  max    = max(x, na.rm = TRUE),
  median = median(x, na.rm = TRUE),
  skew   = skewness(x, na.rm = TRUE),
  kurt   = kurtosis(x, na.rm = TRUE)
)

# Histogram
p1 <- ggplot(d, aes(x = Value)) +
  geom_histogram(aes(y = ..density..), bins = 15,
                 fill = "steelblue", alpha = 0.6) +
  geom_density(color = "darkred", size = 1) +
  theme_minimal(base_size = 13) +
  labs(x = "Value (Int.$ 2020 ha⁻¹ yr⁻¹)", y = "Density",
       title = "Distribution of outcome values")
ggsave("S6_hist_density.png", p1, width = 6, height = 4, dpi = 300)

# ==================================================================
# Final output list
# ==================================================================
Master_Output <- list(
  N                  = nrow(d),
  Year_mean_used     = round(yr_mean, 2),
  Coefficients_levels= tbl,
  Adjusted_R2_levels = adj_r2,
  Wald_F_levels      = wald,
  Coefficients_HAC   = tbl_nw,
  Wald_F_HAC         = wald_nw,
  Coefficients_logDV = tbl_log,
  Wald_F_logDV       = wald_log,
  Significance_check = cmp,
  Diagnostics        = diag_out,
  Clustered_SEs      = clustered_tbl,
  LOSO_summary       = loso_summary,
  LOOCV_summary      = summary_stats,
  CaseStudy_Bav      = pred_bav,
  CaseStudy_BW       = pred_bw,
  Outcome_stats      = outcome_stats
)
